-- adding a table to snowflake db as @sysadmin:

use role sysadmin;
CREATE or REPLACE TABLE GARDEN_PLANTS.VEGGIES.ROOT_DEPTH (
   ROOT_DEPTH_ID number(1), 
   ROOT_DEPTH_CODE text(1), 
   ROOT_DEPTH_NAME text(7), 
   UNIT_OF_MEASURE text(2),
   RANGE_MIN number(2),
   RANGE_MAX number(2)
   ); 

--=======================================================================================

-- adding individual rows to table above using specified vwh:

USE WAREHOUSE COMPUTE_WH;

INSERT INTO ROOT_DEPTH (
	ROOT_DEPTH_ID
  ,	ROOT_DEPTH_CODE
  ,	ROOT_DEPTH_NAME
  ,	UNIT_OF_MEASURE
  ,	RANGE_MIN
  ,	RANGE_MAX 
)

VALUES
(
    1,
    'S',
    'Shallow',
    'cm',
    30,
    45
)
;

USE WAREHOUSE COMPUTE_WH;

INSERT INTO ROOT_DEPTH (
	ROOT_DEPTH_ID
  ,	ROOT_DEPTH_CODE
  ,	ROOT_DEPTH_NAME
  ,	UNIT_OF_MEASURE
  ,	RANGE_MIN
  ,	RANGE_MAX 
)

VALUES
(
    2,
    'M',
    'Medium',
    'cm',
    45,
    60
)
;

USE WAREHOUSE COMPUTE_WH;

INSERT INTO ROOT_DEPTH (
	ROOT_DEPTH_ID
  ,	ROOT_DEPTH_CODE
  ,	ROOT_DEPTH_NAME
  ,	UNIT_OF_MEASURE
  ,	RANGE_MIN
  ,	RANGE_MAX 
)

VALUES
(
    3,
    'D',
    'Deep',
    'cm',
    60,
    90
)
;

--======================================================================================

-- adding multiple rows at once

INSERT into ROOT_DEPTH (
  root_depth_id,
  root_depth_code,
  root_depth_name,
  unit_of_measure, 
  range_min,
  range_max
)
VALUES
  (5,'X','short','in',66,77),
  (8,'Y','tall','cm',98,99)
;

--======================================================================================

-- removing an unwanted row from table:

DELETE
  from root_depth
WHERE
  root_depth_id = 9
;

--======================================================================================

-- changing a value in a field (root_depth) for specific row (root_depth_id):

SET
  root_depth_id = 7
WHERE
  root_depth_id = 9
;

--======================================================================================

-- removing all rows without deleting table:

TRUNCATE TABLE
  root_depth
;

--======================================================================================

-- creating file format (PIPECOLSEP_ONEHEADROW) for importing data from CSV file with pipe delimiters and one header row:

CREATE FILE FORMAT garden_plants.veggies.PIPECOLSEP_ONEHEADROW 
  TYPE = 'CSV' 
    -- csv is used for any flat file (tsv, pipe-separated, etc)
  FIELD_DELIMITER = '|'
    -- pipes as column separators
  SKIP_HEADER = 1 
    -- one header row to skip
;

--======================================================================================

-- creating file format (COMMASEP_DBLQUOT_ONEHEADROW) for importing data from CSV file with comma delimiters where some values also contain commas:

CREATE FILE FORMAT garden_plants.veggies.COMMASEP_DBLQUOT_ONEHEADROW 
  TYPE = 'CSV'
    --csv for comma separated files
  SKIP_HEADER = 1 
    --one header row  
  FIELD_OPTIONALLY_ENCLOSED_BY = '"' 
    --this means that some values will be wrapped in double-quotes bc they have commas in them
;

--=======================================================================================

-- creating API integration in snowflake via AWS API gateway

use role accountadmin;

CREATE or REPLACE API INTEGRATION dora_api_integration
  api_provider = aws_api_gateway
  api_aws_role_arn = 'arn:aws:iam::321463406630:role/snowflakeLearnerAssumedRole'
  enabled = true
  api_allowed_prefixes = ('https://awy6hshxy4.execute-api.us-west-2.amazonaws.com/dev/edu_dora')
;

--=======================================================================================

-- adding function to integrated API (grader) as @accountadmin:

use role accountadmin;  

CREATE or REPLACE EXTERNAL FUNCTION util_db.public.grader(
      step varchar
    , passed boolean
    , actual integer
    , expected integer
    , description varchar)
returns variant
api_integration = dora_api_integration 
context_headers = (current_timestamp, current_account, current_statement, current_account_name) 
as 'https://awy6hshxy4.execute-api.us-west-2.amazonaws.com/dev/edu_dora/grader'
; 

--======================================================================================

-- checking that the grader function is working using specified user/db/schema:

USE role accountadmin;
USE database util_db; 
USE schema public; 

SELECT grader(step, (actual = expected), actual, expected, description) as graded_results from
(SELECT 
 'DORA_IS_WORKING' as step
 ,(select 123) as actual
 ,123 as expected
 ,'Dora is working!' as description
); 

--======================================================================================

-- loading data to table from external stage:

copy into my_table_name
from @external_stage_name
files = ( 'FILE_NAME.txt')
file_format = ( format_name='EXAMPLE_FILEFORMAT' )
;

--=====================================================================================

-- querying data before loading from .tsv file in external stage in util_db.public:

-- no file format, only viewing first field:
select $1
  from @util_db.public.stage_name/FILE_NAME.tsv
;

-- with ff, viewing first 3 fields:  
select $1, $2, $3
  from @util_db.public.stage_name/FILE_NAME.tsv
  (file_format => ff_db_name.ff_schema_name.FF_NAME)
;

--=====================================================================================

-- create new db and table w/ context:

use role sysadmin;

-- create a new database and set the context to use the new database
CREATE DATABASE LIBRARY_CARD_CATALOG COMMENT = 'DWW Lesson 9';
USE DATABASE LIBRARY_CARD_CATALOG;

-- create Author table
CREATE OR REPLACE TABLE AUTHOR (
   AUTHOR_UID NUMBER 
  ,FIRST_NAME VARCHAR(50)
  ,MIDDLE_NAME VARCHAR(50)
  ,LAST_NAME VARCHAR(50)
);

-- insert the first two authors into the Author table
INSERT INTO AUTHOR (
  AUTHOR_UID
  ,FIRST_NAME
  ,MIDDLE_NAME
  ,LAST_NAME
) 
  VALUES
    (1,'Fiona','','Macdonald')
    ,(2,'Gian','Paulo','Faleschini')
;

-- view the new table
SELECT 
  * 
FROM 
  AUTHOR
;

--=====================================================================================

-- create sequence to assign unique IDs for table rows (auto-increment):

CREATE SEQUENCE SEQ_AUTHOR_UID
  start = 1
  increment = 1
  comment = 'Use this to fill in AUTHOR_UID'
;

-- query the sequence as @sysadmin

SELECT SEQ_AUTHOR_UID.nextval
;

--=====================================================================================

-- adding the sequence above to the AUTHOR table as @sysadmin, starting at '3' to account for the existing 2 rows we already added:

use role sysadmin;

-- drop and recreate the counter (sequence) so that it starts at 3:
CREATE OR REPLACE SEQUENCE "LIBRARY_CARD_CATALOG"."PUBLIC"."SEQ_AUTHOR_UID" 
  START 3 
  INCREMENT 1 
  COMMENT = 'Use this to fill in the AUTHOR_UID every time you add a row';

-- add the remaining author records and use the nextval function instead of putting in the numbers:
INSERT INTO AUTHOR(AUTHOR_UID,FIRST_NAME,MIDDLE_NAME,LAST_NAME) 
  VALUES
    (SEQ_AUTHOR_UID.nextval,'Laura','K','Egendorf')
    ,(SEQ_AUTHOR_UID.nextval,'Jan','','Grover')
    ,(SEQ_AUTHOR_UID.nextval,'Jennifer','','Clapp')
    ,(SEQ_AUTHOR_UID.nextval,'Kathleen','','Petelinsek')
;

--===================================================================================

-- creating a second sequence and 2 new tables (book,map):

USE DATABASE LIBRARY_CARD_CATALOG;

-- create a new sequence, this one will be a counter for the book table:
CREATE OR REPLACE SEQUENCE "LIBRARY_CARD_CATALOG"."PUBLIC"."SEQ_BOOK_UID" 
  START 1 
  INCREMENT 1 
  COMMENT = 'Use this to fill in the BOOK_UID everytime you add a row';

-- create the book table and use the NEXTVAL as the default value each time a row is added to the table:
CREATE OR REPLACE TABLE BOOK (
  BOOK_UID NUMBER DEFAULT SEQ_BOOK_UID.nextval
 ,TITLE VARCHAR(50)
 ,YEAR_PUBLISHED NUMBER(4,0)
);

-- insert records into the book table; no need to list anything for the BOOK_UID field because the default setting will take care of it:
INSERT INTO BOOK(TITLE,YEAR_PUBLISHED)
  VALUES
    ('Food',2001)
    ,('Food',2006)
    ,('Food',2008)
    ,('Food',2016)
    ,('Food',2015)
;

-- Create the relationships table (this is sometimes called a "Many-to-Many table"):
CREATE TABLE BOOK_TO_AUTHOR (  
  BOOK_UID NUMBER
  ,AUTHOR_UID NUMBER
);

-- insert rows of the known relationships:
INSERT INTO BOOK_TO_AUTHOR(BOOK_UID,AUTHOR_UID)
  VALUES
    (1,1)  -- this row links the 2001 book to Fiona Macdonald
    ,(1,2)  -- this row links the 2001 book to Gian Paulo Faleschini
    ,(2,3)  -- links 2006 book to Laura K Egendorf
    ,(3,4)  -- links 2008 book to Jan Grover
    ,(4,5)  -- links 2016 book to Jennifer Clapp
    ,(5,6)  -- links 2015 book to Kathleen Petelinsek
;

-- check your work by joining the 3 tables together, should get 1 row for every author
SELECT * 
  FROM book_to_author ba 
    JOIN author a 
      ON ba.author_uid = a.author_uid 
    JOIN book b 
      ON b.book_uid=ba.book_uid
; 

































